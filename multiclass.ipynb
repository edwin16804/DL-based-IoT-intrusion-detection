{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169/169 [02:22<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        flow_duration  Header_Length  Protocol Type  Duration         Rate  \\\n",
      "0            0.000000          54.00           6.00     64.00     0.329807   \n",
      "1            0.000000          57.04           6.33     64.00     4.290556   \n",
      "2            0.000000           0.00           1.00     64.00    33.396799   \n",
      "3            0.328175       76175.00          17.00     64.00  4642.133010   \n",
      "4            0.117320         101.73           6.11     65.91     6.202211   \n",
      "...               ...            ...            ...       ...          ...   \n",
      "238682       0.000000          54.00           6.00     64.00     3.049186   \n",
      "238683       0.000000          54.00           6.00     64.00   183.433732   \n",
      "238684       0.000785          56.29           6.11     64.00   306.952216   \n",
      "238685       0.000901          72.09           6.11     64.64   158.475986   \n",
      "238686       0.000000           0.00           1.00     64.00     1.291274   \n",
      "\n",
      "              Srate  Drate  fin_flag_number  syn_flag_number  rst_flag_number  \\\n",
      "0          0.329807    0.0              1.0              0.0              1.0   \n",
      "1          4.290556    0.0              0.0              0.0              0.0   \n",
      "2         33.396799    0.0              0.0              0.0              0.0   \n",
      "3       4642.133010    0.0              0.0              0.0              0.0   \n",
      "4          6.202211    0.0              0.0              1.0              0.0   \n",
      "...             ...    ...              ...              ...              ...   \n",
      "238682     3.049186    0.0              1.0              0.0              1.0   \n",
      "238683   183.433732    0.0              0.0              0.0              0.0   \n",
      "238684   306.952216    0.0              0.0              1.0              0.0   \n",
      "238685   158.475986    0.0              0.0              0.0              0.0   \n",
      "238686     1.291274    0.0              0.0              0.0              0.0   \n",
      "\n",
      "        ...        Std  Tot size           IAT  Number   Magnitue     Radius  \\\n",
      "0       ...   0.000000     54.00  8.334383e+07     9.5  10.392305   0.000000   \n",
      "1       ...   2.822973     57.04  8.292607e+07     9.5  10.464666   4.010353   \n",
      "2       ...   0.000000     42.00  8.312799e+07     9.5   9.165151   0.000000   \n",
      "3       ...   0.000000     50.00  8.301570e+07     9.5  10.000000   0.000000   \n",
      "4       ...  23.113111     57.88  8.297300e+07     9.5  11.346876  32.716243   \n",
      "...     ...        ...       ...           ...     ...        ...        ...   \n",
      "238682  ...   0.000000     54.00  8.334449e+07     9.5  10.392305   0.000000   \n",
      "238683  ...   0.000000     54.00  8.331392e+07     9.5  10.392305   0.000000   \n",
      "238684  ...   0.140764     54.21  8.308883e+07     9.5  10.395538   0.200659   \n",
      "238685  ...   2.450404     55.48  8.333177e+07     9.5  10.456522   3.475801   \n",
      "238686  ...   0.000000     42.00  8.312453e+07     9.5   9.165151   0.000000   \n",
      "\n",
      "         Covariance  Variance  Weight              label  \n",
      "0          0.000000      0.00  141.55   DDoS-RSTFINFlood  \n",
      "1        160.987842      0.05  141.55      DoS-TCP_Flood  \n",
      "2          0.000000      0.00  141.55    DDoS-ICMP_Flood  \n",
      "3          0.000000      0.00  141.55      DoS-UDP_Flood  \n",
      "4       3016.808286      0.19  141.55      DoS-SYN_Flood  \n",
      "...             ...       ...     ...                ...  \n",
      "238682     0.000000      0.00  141.55   DDoS-RSTFINFlood  \n",
      "238683     0.000000      0.00  141.55  DDoS-PSHACK_Flood  \n",
      "238684     0.671167      0.03  141.55     DDoS-SYN_Flood  \n",
      "238685    55.994224      0.17  141.55  DDoS-PSHACK_Flood  \n",
      "238686     0.000000      0.00  141.55    DDoS-ICMP_Flood  \n",
      "\n",
      "[238687 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIRECTORY = 'C:/Users/EDWIN/Downloads/CICIoT2023'\n",
    "df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]\n",
    "df_sets.sort()\n",
    "dfs=[]\n",
    "#Dropping NA values\n",
    "for file in tqdm(df_sets):\n",
    "    file_path=os.path.join(DATASET_DIRECTORY,file)\n",
    "    df=pd.read_csv(file_path)\n",
    "    df.dropna()\n",
    "    dfs.append(df)\n",
    "    \n",
    "print(dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n",
      "(34,)\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    print(df['label'].value_counts().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BrowserHijacking': 1, 'MITM-ArpSpoofing': 2, 'DNS_Spoofing': 3, 'VulnerabilityScan': 4, 'SqlInjection': 5, 'Recon-PingSweep': 6, 'DoS-TCP_Flood': 7, 'Recon-HostDiscovery': 8, 'Recon-OSScan': 9, 'XSS': 10, 'Uploading_Attack': 11, 'DDoS-SynonymousIP_Flood': 12, 'DDoS-ICMP_Flood': 13, 'DDoS-UDP_Fragmentation': 14, 'DDoS-RSTFINFlood': 15, 'DDoS-SYN_Flood': 16, 'DDoS-UDP_Flood': 17, 'DDoS-ACK_Fragmentation': 18, 'Mirai-greeth_flood': 19, 'DDoS-SlowLoris': 20, 'Mirai-udpplain': 21, 'DoS-UDP_Flood': 22, 'DDoS-TCP_Flood': 23, 'BenignTraffic': 24, 'DictionaryBruteForce': 25, 'DoS-HTTP_Flood': 26, 'DoS-SYN_Flood': 27, 'DDoS-PSHACK_Flood': 28, 'DDoS-ICMP_Fragmentation': 29, 'Backdoor_Malware': 30, 'DDoS-HTTP_Flood': 31, 'Mirai-greip_flood': 32, 'Recon-PortScan': 33, 'CommandInjection': 34}\n"
     ]
    }
   ],
   "source": [
    "df=dfs[0]\n",
    "labels=set(df['label'].tolist())\n",
    "cat=1\n",
    "labels_dict={}\n",
    "for i in labels:\n",
    "    if i not in labels_dict:\n",
    "        labels_dict[i]=cat\n",
    "    cat+=1\n",
    "print(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169it [00:02, 67.70it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx,df in tqdm(enumerate(dfs)):\n",
    "    df['label']=df['label'].map(labels_dict)\n",
    "    dfs[idx]=df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "13    36554\n",
       "17    27626\n",
       "23    23149\n",
       "28    21210\n",
       "16    20739\n",
       "15    20669\n",
       "12    18189\n",
       "22    16957\n",
       "7     13630\n",
       "27    10275\n",
       "24     5600\n",
       "19     5016\n",
       "21     4661\n",
       "32     3758\n",
       "29     2377\n",
       "2      1614\n",
       "18     1505\n",
       "14     1484\n",
       "3       925\n",
       "8       697\n",
       "9       517\n",
       "33      430\n",
       "26      414\n",
       "4       210\n",
       "31      169\n",
       "20      106\n",
       "25       63\n",
       "5        31\n",
       "1        30\n",
       "34       28\n",
       "30       22\n",
       "10       18\n",
       "11        8\n",
       "6         6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=dfs[0]\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169it [03:03,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238687, 35)\n",
      "(218805, 36)\n",
      "(275258, 35)\n",
      "(231023, 35)\n",
      "(227491, 34)\n",
      "(240046, 35)\n",
      "(233793, 36)\n",
      "(227910, 36)\n",
      "(246327, 35)\n",
      "(227616, 35)\n",
      "(251392, 35)\n",
      "(221928, 35)\n",
      "(238476, 36)\n",
      "(238761, 36)\n",
      "(215838, 36)\n",
      "(268649, 35)\n",
      "(232885, 36)\n",
      "(223444, 36)\n",
      "(234430, 36)\n",
      "(231063, 35)\n",
      "(237151, 36)\n",
      "(223401, 35)\n",
      "(252212, 35)\n",
      "(262062, 35)\n",
      "(225725, 36)\n",
      "(447625, 35)\n",
      "(236152, 35)\n",
      "(221014, 36)\n",
      "(251225, 36)\n",
      "(251676, 35)\n",
      "(238350, 35)\n",
      "(228730, 36)\n",
      "(227636, 35)\n",
      "(447774, 35)\n",
      "(232228, 36)\n",
      "(252744, 36)\n",
      "(439212, 34)\n",
      "(214963, 36)\n",
      "(236660, 36)\n",
      "(437362, 35)\n",
      "(230365, 34)\n",
      "(445281, 36)\n",
      "(222425, 36)\n",
      "(250954, 36)\n",
      "(231980, 35)\n",
      "(247290, 35)\n",
      "(235566, 35)\n",
      "(239086, 35)\n",
      "(219877, 35)\n",
      "(248997, 35)\n",
      "(233625, 36)\n",
      "(251256, 36)\n",
      "(445425, 35)\n",
      "(243279, 35)\n",
      "(235625, 35)\n",
      "(222384, 35)\n",
      "(235026, 35)\n",
      "(429585, 36)\n",
      "(236995, 36)\n",
      "(245184, 35)\n",
      "(254147, 35)\n",
      "(239643, 36)\n",
      "(441027, 35)\n",
      "(237426, 36)\n",
      "(263065, 35)\n",
      "(244926, 36)\n",
      "(216084, 35)\n",
      "(267928, 35)\n",
      "(224089, 35)\n",
      "(240206, 35)\n",
      "(229776, 36)\n",
      "(277720, 34)\n",
      "(260695, 35)\n",
      "(235721, 34)\n",
      "(247037, 36)\n",
      "(444334, 36)\n",
      "(446795, 35)\n",
      "(435700, 35)\n",
      "(434834, 36)\n",
      "(451034, 35)\n",
      "(235689, 35)\n",
      "(230739, 35)\n",
      "(230193, 36)\n",
      "(228653, 36)\n",
      "(224827, 35)\n",
      "(242969, 36)\n",
      "(243026, 36)\n",
      "(236324, 36)\n",
      "(226970, 36)\n",
      "(242365, 35)\n",
      "(240767, 35)\n",
      "(260018, 35)\n",
      "(211834, 35)\n",
      "(253869, 35)\n",
      "(428621, 35)\n",
      "(444222, 36)\n",
      "(255132, 34)\n",
      "(244583, 36)\n",
      "(446795, 36)\n",
      "(241728, 34)\n",
      "(225908, 36)\n",
      "(233745, 36)\n",
      "(231907, 35)\n",
      "(252487, 36)\n",
      "(223529, 35)\n",
      "(231756, 35)\n",
      "(250850, 35)\n",
      "(223506, 35)\n",
      "(231694, 36)\n",
      "(262918, 36)\n",
      "(236752, 35)\n",
      "(269253, 36)\n",
      "(253575, 35)\n",
      "(451498, 36)\n",
      "(239887, 36)\n",
      "(218872, 36)\n",
      "(244797, 36)\n",
      "(243486, 35)\n",
      "(219849, 36)\n",
      "(239892, 36)\n",
      "(235181, 35)\n",
      "(246561, 35)\n",
      "(248224, 35)\n",
      "(256571, 35)\n",
      "(248704, 35)\n",
      "(448643, 36)\n",
      "(234604, 36)\n",
      "(447735, 34)\n",
      "(239666, 35)\n",
      "(229641, 34)\n",
      "(256955, 35)\n",
      "(445755, 36)\n",
      "(239097, 35)\n",
      "(239831, 36)\n",
      "(243649, 35)\n",
      "(239203, 34)\n",
      "(444704, 35)\n",
      "(256459, 36)\n",
      "(446836, 36)\n",
      "(242144, 36)\n",
      "(449215, 36)\n",
      "(223999, 35)\n",
      "(260694, 36)\n",
      "(239202, 35)\n",
      "(244859, 36)\n",
      "(442721, 35)\n",
      "(227148, 35)\n",
      "(237858, 36)\n",
      "(235009, 35)\n",
      "(445891, 36)\n",
      "(232166, 34)\n",
      "(229627, 36)\n",
      "(446751, 35)\n",
      "(435001, 35)\n",
      "(232216, 35)\n",
      "(229855, 35)\n",
      "(256428, 35)\n",
      "(239934, 35)\n",
      "(230476, 35)\n",
      "(231318, 36)\n",
      "(231306, 35)\n",
      "(232463, 35)\n",
      "(439594, 36)\n",
      "(233587, 35)\n",
      "(447638, 36)\n",
      "(444417, 35)\n",
      "(449009, 36)\n",
      "(227688, 36)\n",
      "(234745, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for idx,df in tqdm(enumerate(dfs)):\n",
    "    corr=df.corr()\n",
    "    columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "    for i in range(corr.shape[0]):\n",
    "        for j in range(i+1, corr.shape[0]):\n",
    "            if corr.iloc[i,j] >= 0.9:\n",
    "                if columns[j]:\n",
    "                    columns[j] = False\n",
    "    selected_columns = df.columns[columns]\n",
    "    selected_columns.shape\n",
    "    dfs[idx]=df[selected_columns]\n",
    "\n",
    "for df in dfs:\n",
    "    print(df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169it [00:34,  4.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Get the intersection of selected columns (common across all dataframes)\n",
    "common_columns = set(dfs[0].columns)  # Start with the columns from the first dataframe\n",
    "\n",
    "for df in dfs[1:]:\n",
    "    common_columns = common_columns.intersection(set(df.columns))\n",
    "\n",
    "common_columns = list(common_columns)\n",
    "\n",
    "# Step 2: Reindex all dataframes to use only the common columns\n",
    "for idx, df in tqdm(enumerate(dfs)):\n",
    "    dfs[idx] = df[common_columns]\n",
    "\n",
    "# Now all dfs have the same number of columns (common columns), so you can fit the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238687, 34)\n",
      "(218805, 34)\n",
      "(275258, 34)\n",
      "(231023, 34)\n",
      "(227491, 34)\n",
      "(240046, 34)\n",
      "(233793, 34)\n",
      "(227910, 34)\n",
      "(246327, 34)\n",
      "(227616, 34)\n",
      "(251392, 34)\n",
      "(221928, 34)\n",
      "(238476, 34)\n",
      "(238761, 34)\n",
      "(215838, 34)\n",
      "(268649, 34)\n",
      "(232885, 34)\n",
      "(223444, 34)\n",
      "(234430, 34)\n",
      "(231063, 34)\n",
      "(237151, 34)\n",
      "(223401, 34)\n",
      "(252212, 34)\n",
      "(262062, 34)\n",
      "(225725, 34)\n",
      "(447625, 34)\n",
      "(236152, 34)\n",
      "(221014, 34)\n",
      "(251225, 34)\n",
      "(251676, 34)\n",
      "(238350, 34)\n",
      "(228730, 34)\n",
      "(227636, 34)\n",
      "(447774, 34)\n",
      "(232228, 34)\n",
      "(252744, 34)\n",
      "(439212, 34)\n",
      "(214963, 34)\n",
      "(236660, 34)\n",
      "(437362, 34)\n",
      "(230365, 34)\n",
      "(445281, 34)\n",
      "(222425, 34)\n",
      "(250954, 34)\n",
      "(231980, 34)\n",
      "(247290, 34)\n",
      "(235566, 34)\n",
      "(239086, 34)\n",
      "(219877, 34)\n",
      "(248997, 34)\n",
      "(233625, 34)\n",
      "(251256, 34)\n",
      "(445425, 34)\n",
      "(243279, 34)\n",
      "(235625, 34)\n",
      "(222384, 34)\n",
      "(235026, 34)\n",
      "(429585, 34)\n",
      "(236995, 34)\n",
      "(245184, 34)\n",
      "(254147, 34)\n",
      "(239643, 34)\n",
      "(441027, 34)\n",
      "(237426, 34)\n",
      "(263065, 34)\n",
      "(244926, 34)\n",
      "(216084, 34)\n",
      "(267928, 34)\n",
      "(224089, 34)\n",
      "(240206, 34)\n",
      "(229776, 34)\n",
      "(277720, 34)\n",
      "(260695, 34)\n",
      "(235721, 34)\n",
      "(247037, 34)\n",
      "(444334, 34)\n",
      "(446795, 34)\n",
      "(435700, 34)\n",
      "(434834, 34)\n",
      "(451034, 34)\n",
      "(235689, 34)\n",
      "(230739, 34)\n",
      "(230193, 34)\n",
      "(228653, 34)\n",
      "(224827, 34)\n",
      "(242969, 34)\n",
      "(243026, 34)\n",
      "(236324, 34)\n",
      "(226970, 34)\n",
      "(242365, 34)\n",
      "(240767, 34)\n",
      "(260018, 34)\n",
      "(211834, 34)\n",
      "(253869, 34)\n",
      "(428621, 34)\n",
      "(444222, 34)\n",
      "(255132, 34)\n",
      "(244583, 34)\n",
      "(446795, 34)\n",
      "(241728, 34)\n",
      "(225908, 34)\n",
      "(233745, 34)\n",
      "(231907, 34)\n",
      "(252487, 34)\n",
      "(223529, 34)\n",
      "(231756, 34)\n",
      "(250850, 34)\n",
      "(223506, 34)\n",
      "(231694, 34)\n",
      "(262918, 34)\n",
      "(236752, 34)\n",
      "(269253, 34)\n",
      "(253575, 34)\n",
      "(451498, 34)\n",
      "(239887, 34)\n",
      "(218872, 34)\n",
      "(244797, 34)\n",
      "(243486, 34)\n",
      "(219849, 34)\n",
      "(239892, 34)\n",
      "(235181, 34)\n",
      "(246561, 34)\n",
      "(248224, 34)\n",
      "(256571, 34)\n",
      "(248704, 34)\n",
      "(448643, 34)\n",
      "(234604, 34)\n",
      "(447735, 34)\n",
      "(239666, 34)\n",
      "(229641, 34)\n",
      "(256955, 34)\n",
      "(445755, 34)\n",
      "(239097, 34)\n",
      "(239831, 34)\n",
      "(243649, 34)\n",
      "(239203, 34)\n",
      "(444704, 34)\n",
      "(256459, 34)\n",
      "(446836, 34)\n",
      "(242144, 34)\n",
      "(449215, 34)\n",
      "(223999, 34)\n",
      "(260694, 34)\n",
      "(239202, 34)\n",
      "(244859, 34)\n",
      "(442721, 34)\n",
      "(227148, 34)\n",
      "(237858, 34)\n",
      "(235009, 34)\n",
      "(445891, 34)\n",
      "(232166, 34)\n",
      "(229627, 34)\n",
      "(446751, 34)\n",
      "(435001, 34)\n",
      "(232216, 34)\n",
      "(229855, 34)\n",
      "(256428, 34)\n",
      "(239934, 34)\n",
      "(230476, 34)\n",
      "(231318, 34)\n",
      "(231306, 34)\n",
      "(232463, 34)\n",
      "(439594, 34)\n",
      "(233587, 34)\n",
      "(447638, 34)\n",
      "(444417, 34)\n",
      "(449009, 34)\n",
      "(227688, 34)\n",
      "(234745, 34)\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">83,456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,515</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m83,456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)             │         \u001b[38;5;34m4,515\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">87,971</span> (343.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m87,971\u001b[0m (343.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">87,971</span> (343.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m87,971\u001b[0m (343.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "timesteps=1\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(timesteps, dfs[0].shape[1]), activation='relu'))\n",
    "model.add(Dense(units=35, activation='softmax'))  \n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m4774/4774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.1069 - loss: 182629.4844 - val_accuracy: 0.1086 - val_loss: 20348.4277\n",
      "Epoch 2/5\n",
      "\u001b[1m4774/4774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.1283 - loss: 12769.8359 - val_accuracy: 0.1694 - val_loss: 36.4164\n",
      "Epoch 3/5\n",
      "\u001b[1m4774/4774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1619 - loss: 33.2597 - val_accuracy: 0.1673 - val_loss: 10.6047\n",
      "Epoch 4/5\n",
      "\u001b[1m4774/4774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.1572 - loss: 9.4309 - val_accuracy: 0.1568 - val_loss: 2.8559\n",
      "Epoch 5/5\n",
      "\u001b[1m4774/4774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1534 - loss: 2.7764 - val_accuracy: 0.1566 - val_loss: 2.8000\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step\n",
      "1492/1492 - 1s - 673us/step - accuracy: 0.1580 - loss: 54.4460\n",
      "Test Accuracy: 0.15800829231739044\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.callbacks import EarlyStopping , ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "early_stopping=EarlyStopping(monitor='val_loss',min_delta=0,patience=5,verbose=1,mode='min',restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "df=dfs[0]\n",
    "scaler = MinMaxScaler()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y=df['label']\n",
    "data = df.values\n",
    "data_reshaped = data.reshape((data.shape[0], timesteps, data.shape[1]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_reshaped, y, test_size=0.2, random_state=42)\n",
    "class_weights = compute_class_weight(class_weight='balanced',classes=np.unique(y_train),y=y_train)\n",
    "class_weights_dict = {class_index: weight for class_index, weight in enumerate(class_weights)}\n",
    "\n",
    "y_true += list(y_test)\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32, callbacks=[early_stopping],validation_split=0.2)\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred += list((y_pred_probs > 0.5).astype(int))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
